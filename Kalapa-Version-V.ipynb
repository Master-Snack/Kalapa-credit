{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = pd.read_csv(\"data/train.csv\")\n",
    "app_test = pd.read_csv(\"data/test.csv\")\n",
    "sample = pd.read_csv(\"data/simple_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (53030, 195)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>Field_1</th>\n",
       "      <th>Field_2</th>\n",
       "      <th>Field_3</th>\n",
       "      <th>Field_4</th>\n",
       "      <th>Field_5</th>\n",
       "      <th>Field_6</th>\n",
       "      <th>Field_7</th>\n",
       "      <th>Field_8</th>\n",
       "      <th>...</th>\n",
       "      <th>partner5_H</th>\n",
       "      <th>partner5_K</th>\n",
       "      <th>partner5_L</th>\n",
       "      <th>brief</th>\n",
       "      <th>num_of_phone</th>\n",
       "      <th>Field_78</th>\n",
       "      <th>Field_79</th>\n",
       "      <th>Field_80</th>\n",
       "      <th>Field_81</th>\n",
       "      <th>Field_82</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-24T03:39:02.854Z</td>\n",
       "      <td>2019-07-31T20:10:02Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GH</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cb1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-17T07:15:26.367Z</td>\n",
       "      <td>2019-01-17T07:17:45Z</td>\n",
       "      <td>2.0</td>\n",
       "      <td>T1</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.769445</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.769445</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.769445</td>\n",
       "      <td>6.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                   Field_1               Field_2  Field_3 Field_4  \\\n",
       "0   0      1  2019-07-24T03:39:02.854Z  2019-07-31T20:10:02Z      1.0      GH   \n",
       "1   1      0                       NaN                   NaN      NaN     NaN   \n",
       "2   2      0  2019-01-17T07:15:26.367Z  2019-01-17T07:17:45Z      2.0      T1   \n",
       "3   3      0                       NaN                   NaN      NaN     NaN   \n",
       "4   4      1                       NaN                   NaN      NaN     NaN   \n",
       "\n",
       "      Field_5     Field_6     Field_7     Field_8  ... partner5_H  partner5_K  \\\n",
       "0  2018-12-27  2018-12-27  2019-01-01  2019-07-31  ...        0.0         0.0   \n",
       "1         NaN         NaN         NaN         NaN  ...        0.0         0.0   \n",
       "2  2019-01-17  2019-01-17  2019-01-01  2019-12-31  ...        0.0         0.0   \n",
       "3         NaN         NaN         NaN         NaN  ...        NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN  ...        NaN         NaN   \n",
       "\n",
       "  partner5_L brief  num_of_phone  Field_78   Field_79  Field_80  Field_81  \\\n",
       "0        0.0   cb1           1.0       NaN        NaN       NaN       NaN   \n",
       "1        0.0     4           1.0       NaN        NaN       NaN       NaN   \n",
       "2        0.0     1           1.0      33.0  10.769445  6.466667       0.0   \n",
       "3        NaN     1           1.0      33.0  10.769445  6.466667       0.0   \n",
       "4        NaN     1           1.0      33.0  10.769445  6.466667       0.0   \n",
       "\n",
       "  Field_82  \n",
       "0        1  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        3  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training data shape: ', app_train.shape)\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (20381, 194)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Field_1</th>\n",
       "      <th>Field_2</th>\n",
       "      <th>Field_3</th>\n",
       "      <th>Field_4</th>\n",
       "      <th>Field_5</th>\n",
       "      <th>Field_6</th>\n",
       "      <th>Field_7</th>\n",
       "      <th>Field_8</th>\n",
       "      <th>Field_9</th>\n",
       "      <th>...</th>\n",
       "      <th>partner5_H</th>\n",
       "      <th>partner5_K</th>\n",
       "      <th>partner5_L</th>\n",
       "      <th>brief</th>\n",
       "      <th>num_of_phone</th>\n",
       "      <th>Field_78</th>\n",
       "      <th>Field_79</th>\n",
       "      <th>Field_80</th>\n",
       "      <th>Field_81</th>\n",
       "      <th>Field_82</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53030</td>\n",
       "      <td>2019-10-14T01:37:41.959Z</td>\n",
       "      <td>2019-10-14T01:37:41.959Z</td>\n",
       "      <td>2.0</td>\n",
       "      <td>T1</td>\n",
       "      <td>8/27/2019</td>\n",
       "      <td>8/27/2019</td>\n",
       "      <td>9/24/2019</td>\n",
       "      <td>9/23/2020</td>\n",
       "      <td>8/27/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53031</td>\n",
       "      <td>2019-09-10T09:20:40.066Z</td>\n",
       "      <td>2019-09-11T07:53:44Z</td>\n",
       "      <td>2.0</td>\n",
       "      <td>T1</td>\n",
       "      <td>9/10/2019</td>\n",
       "      <td>9/10/2019</td>\n",
       "      <td>9/14/2019</td>\n",
       "      <td>9/13/2020</td>\n",
       "      <td>9/10/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>notfound</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53033</td>\n",
       "      <td>2019-10-21T03:29:30.074Z</td>\n",
       "      <td>2019-10-21T04:17:26Z</td>\n",
       "      <td>2.0</td>\n",
       "      <td>T1</td>\n",
       "      <td>10/21/2019</td>\n",
       "      <td>10/21/2019</td>\n",
       "      <td>11/15/2019</td>\n",
       "      <td>11/14/2020</td>\n",
       "      <td>10/21/2019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                   Field_1                   Field_2  Field_3 Field_4  \\\n",
       "0  53030  2019-10-14T01:37:41.959Z  2019-10-14T01:37:41.959Z      2.0      T1   \n",
       "1  53031  2019-09-10T09:20:40.066Z      2019-09-11T07:53:44Z      2.0      T1   \n",
       "2  53032                       NaN                       NaN      NaN     NaN   \n",
       "3  53033  2019-10-21T03:29:30.074Z      2019-10-21T04:17:26Z      2.0      T1   \n",
       "4  53034                       NaN                       NaN      NaN     NaN   \n",
       "\n",
       "      Field_5     Field_6     Field_7     Field_8     Field_9  ...  \\\n",
       "0   8/27/2019   8/27/2019   9/24/2019   9/23/2020   8/27/2019  ...   \n",
       "1   9/10/2019   9/10/2019   9/14/2019   9/13/2020   9/10/2019  ...   \n",
       "2         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "3  10/21/2019  10/21/2019  11/15/2019  11/14/2020  10/21/2019  ...   \n",
       "4         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "\n",
       "   partner5_H partner5_K partner5_L     brief  num_of_phone Field_78  \\\n",
       "0         0.0        0.0        0.0       NaN           2.0      NaN   \n",
       "1         0.0        0.0        0.0  notfound           1.0      NaN   \n",
       "2         0.0        0.0        0.0         0           1.0      NaN   \n",
       "3         0.0        0.0        0.0       NaN           1.0      NaN   \n",
       "4         0.0        0.0        0.0         3           1.0     27.0   \n",
       "\n",
       "   Field_79  Field_80 Field_81  Field_82  \n",
       "0       NaN       NaN      NaN         1  \n",
       "1       NaN       NaN      NaN         1  \n",
       "2       NaN       NaN      NaN         1  \n",
       "3       NaN       NaN      NaN         1  \n",
       "4       NaN      27.0     27.0         1  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training data shape: ', app_test.shape)\n",
    "app_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Examine Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(df):\n",
    "    mis_val = df.isnull().sum() #tổng các giá trị còn thiếu\n",
    "    mis_val_per = 100 * df.isnull().sum()/len(df) #Phần trăm các giá trị còn thiếu\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_per], axis=1) #Tạo thành bảng để thể hiện 2 giá trị trên\n",
    "    mis_val_table_rename = mis_val_table.rename(\n",
    "    columns = {0: \"Missing\", 1 : \"Percent %\"})\n",
    "    #Sắp xếp bảng theo tỉ lệ phần trăm giảm dần\n",
    "    mis_val_table_rename = mis_val_table_rename[mis_val_table_rename.iloc[:, 1] != 0].sort_values(\"Percent %\", ascending=False).round(1)\n",
    "    print(\"Có tất cả \" + str(df.shape[1]) + \" cột.\\n\"\n",
    "          \"Trog đó có \" + str(mis_val_table_rename.shape[0]) + \" cột bị thiếu data\")\n",
    "    return mis_val_table_rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Có tất cả 195 cột.\n",
      "Trog đó có 192 cột bị thiếu data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing</th>\n",
       "      <th>Percent %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Field_35</th>\n",
       "      <td>46198</td>\n",
       "      <td>87.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field_12</th>\n",
       "      <td>45650</td>\n",
       "      <td>86.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field_11</th>\n",
       "      <td>45616</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field_18</th>\n",
       "      <td>44643</td>\n",
       "      <td>84.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maCv</th>\n",
       "      <td>43882</td>\n",
       "      <td>82.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner1_K</th>\n",
       "      <td>4747</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner1_H</th>\n",
       "      <td>4747</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner0_D</th>\n",
       "      <td>4747</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_of_phone</th>\n",
       "      <td>2512</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brief</th>\n",
       "      <td>252</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missing  Percent %\n",
       "Field_35        46198       87.1\n",
       "Field_12        45650       86.1\n",
       "Field_11        45616       86.0\n",
       "Field_18        44643       84.2\n",
       "maCv            43882       82.7\n",
       "...               ...        ...\n",
       "partner1_K       4747        9.0\n",
       "partner1_H       4747        9.0\n",
       "partner0_D       4747        9.0\n",
       "num_of_phone     2512        4.7\n",
       "brief             252        0.5\n",
       "\n",
       "[192 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = missing_values(app_train)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi đến lúc xây dựng các mô hình học máy của mình, chúng ta sẽ phải điền vào các giá trị còn thiếu này (được gọi là áp đặt). Trong công việc sau này, chúng tôi sẽ sử dụng các mô hình như XGBoost có thể xử lý các giá trị bị thiếu mà không cần áp đặt. Một tùy chọn khác sẽ là loại bỏ các cột có tỷ lệ giá trị bị thiếu cao, mặc dù không thể biết trước liệu các cột này có hữu ích cho mô hình của chúng tôi hay không. Do đó, chúng tôi sẽ giữ tất cả các cột ngay bây giờ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Column Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    133\n",
       "object      59\n",
       "int64        3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Số lượng object trong mỗi columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Field_1                   21506\n",
       "Field_2                   18667\n",
       "Field_4                       2\n",
       "Field_5                    1901\n",
       "Field_6                    1870\n",
       "Field_7                    1199\n",
       "Field_8                    1392\n",
       "Field_9                    1929\n",
       "Field_11                    836\n",
       "Field_12                      7\n",
       "Field_15                   1539\n",
       "Field_18                   6587\n",
       "Field_25                   1613\n",
       "Field_32                   1527\n",
       "Field_33                   1753\n",
       "Field_34                   2635\n",
       "Field_35                    632\n",
       "gioiTinh                      2\n",
       "diaChi                    21057\n",
       "Field_36                     34\n",
       "Field_38                      6\n",
       "Field_40                    541\n",
       "Field_43                   3605\n",
       "Field_44                   9901\n",
       "Field_45                  10957\n",
       "Field_46                  14311\n",
       "Field_47                      5\n",
       "Field_48                  12650\n",
       "Field_49                  12818\n",
       "Field_54                     44\n",
       "Field_55                    220\n",
       "Field_56                   1345\n",
       "Field_61                     35\n",
       "Field_62                      6\n",
       "Field_65                     10\n",
       "Field_66                      8\n",
       "Field_68                  10944\n",
       "maCv                       3589\n",
       "info_social_sex               2\n",
       "data.basic_info.locale       24\n",
       "currentLocationCity         876\n",
       "currentLocationCountry       48\n",
       "currentLocationName        1087\n",
       "currentLocationState        201\n",
       "homeTownCity                886\n",
       "homeTownCountry              38\n",
       "homeTownName               1133\n",
       "homeTownState               148\n",
       "F_startDate                 239\n",
       "F_endDate                   229\n",
       "E_startDate                 237\n",
       "E_endDate                   228\n",
       "C_startDate                 197\n",
       "C_endDate                   190\n",
       "G_startDate                 239\n",
       "G_endDate                   230\n",
       "A_startDate                 399\n",
       "A_endDate                   351\n",
       "brief                        20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = app_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2566e93d9108>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapp_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;31m# Train on the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapp_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[1;31m# Transform both training and testing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mapp_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapp_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \"\"\"\n\u001b[0;32m    239\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    115\u001b[0m             types = sorted(t.__qualname__\n\u001b[0;32m    116\u001b[0m                            for t in set(type(v) for v in values))\n\u001b[1;32m--> 117\u001b[1;33m             raise TypeError(\"Encoders require their input to be uniformly \"\n\u001b[0m\u001b[0;32m    118\u001b[0m                             f\"strings or numbers. Got {types}\")\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtypes == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app_train[col].unique())) <= 10:\n",
    "            # Train on the training data\n",
    "            le.fit(app_train[col])\n",
    "            # Transform both training and testing data\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            app_test[col] = le.transform(app_test[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
